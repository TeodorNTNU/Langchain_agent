{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Example: LLM with Tools\n",
    "This Notebook uses an efficient tool calling approach that allows for parallel tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade langchain langsmith langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI keys from .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Demos\"\n",
    "\n",
    "# Initialize OpenWeatherMap\n",
    "OPENWEATHERMAP_API_KEY = os.getenv(\"OPENWEATHERMAP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Initialize SQLite database\n",
    "conn = sqlite3.connect('api_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables for storing weather and electricity price data\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS weather_data (\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    date_query TEXT,\n",
    "    date TEXT,\n",
    "    temperature REAL\n",
    ")\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS electricity_data (\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    date_query TEXT,\n",
    "    date TEXT,\n",
    "    price REAL\n",
    ")\n",
    "''')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically for tools\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = {\n",
    "    \"NO1\": (\"Oslo\", (59.9139, 10.7522)),\n",
    "    \"NO2\": (\"Kristiansand\", (58.1467, 7.9956)),\n",
    "    \"NO3\": (\"Trondheim\", (63.4305, 10.3951)),\n",
    "    \"NO4\": (\"Tromsø\", (69.6492, 18.9553)),\n",
    "    \"NO5\": (\"Bergen\", (60.3928, 5.3221)),\n",
    "}\n",
    "\n",
    "class ElectricityPriceRequest(BaseModel):\n",
    "    city: str = Field(description=\"City\")\n",
    "    state: str = Field(description=\"State or region\")\n",
    "    date_query: str = Field(description=\"Date query\")\n",
    "\n",
    "def get_coordinates(city_name: str, state: str) -> tuple:\n",
    "    geolocator = Nominatim(user_agent=\"electricity_price_api\")\n",
    "    location = geolocator.geocode(f\"{city_name}, {state}\")\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_nearest_region(lat: float, lon: float) -> str:\n",
    "    min_distance = float(\"inf\")\n",
    "    nearest_region = None\n",
    "    for region, (city, coordinates) in REGIONS.items():\n",
    "        distance = geodesic((lat, lon), coordinates).kilometers\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_region = region\n",
    "    return nearest_region\n",
    "\n",
    "def fetch_electricity_prices(year: str, month: str, day: str, region: str) -> str:\n",
    "    url = f\"https://www.hvakosterstrommen.no/api/v1/prices/{year}/{month}-{day}_{region}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return json.dumps(response.json(), indent=4)\n",
    "    else:\n",
    "        return f\"Error fetching data: {response.status_code}\"\n",
    "\n",
    "def get_electricity_prices(city: str, state: str, date_query: str):\n",
    "    coordinates = get_coordinates(city, state)\n",
    "    if not coordinates:\n",
    "        return {\"error\": \"City not found\"}\n",
    "    \n",
    "    lat, lon = coordinates\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if date_query.lower() == \"today\":\n",
    "        start_date = end_date\n",
    "    elif date_query.lower() == \"yesterday\":\n",
    "        start_date = (datetime.now() - timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "        end_date = start_date\n",
    "    elif \"last\" in date_query.lower():\n",
    "        if \"10 days\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(10)).strftime(\"%Y-%m-%d\")\n",
    "        elif \"30 days\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(30)).strftime(\"%Y-%m-%d\")\n",
    "        elif \"three months\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(90)).strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            return {\"error\": \"Invalid date query\"}\n",
    "    else:\n",
    "        try:\n",
    "            start_date, end_date = date_query.split('/')\n",
    "            datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            return {\"error\": \"Invalid date format. Use YYYY-MM-DD or predefined ranges.\"}\n",
    "\n",
    "    nearest_region = find_nearest_region(lat, lon)\n",
    "    if nearest_region:\n",
    "        prices = fetch_electricity_prices(start_date[:4], start_date[5:7], start_date[8:10], nearest_region)\n",
    "        return prices\n",
    "    else:\n",
    "        return \"Could not determine the nearest region.\"\n",
    "\n",
    "electricity_tool = StructuredTool.from_function(\n",
    "    func=get_electricity_prices,\n",
    "    name=\"Fetch_Electricity_Prices\",\n",
    "    description=\"Fetch electricity prices from a specified city and state, with a date query\",\n",
    "    args_schema=ElectricityPriceRequest,\n",
    "    return_direct=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchRequest(BaseModel):\n",
    "    input: str = Field(description=\"Search query\")\n",
    "\n",
    "def web_search(input: str) -> str:\n",
    "    \"\"\"Runs web search.\"\"\"\n",
    "    web_search_tool = TavilySearchResults()\n",
    "    docs = web_search_tool.invoke({\"query\": input})\n",
    "    return docs\n",
    "\n",
    "web_search_tool = StructuredTool.from_function(\n",
    "    func=web_search,\n",
    "    name=\"Web_Search\",\n",
    "    description=\"Runs a web search\",\n",
    "    args_schema=WebSearchRequest,\n",
    "    return_direct=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherRequest(BaseModel):\n",
    "    city: str = Field(description=\"City\")\n",
    "    state: str = Field(description=\"State or region\")\n",
    "    date_query: str = Field(description=\"Date query\")\n",
    "\n",
    "def get_coordinates(city_name: str, state: str) -> tuple:\n",
    "    geolocator = Nominatim(user_agent=\"weather_api\")\n",
    "    location = geolocator.geocode(f\"{city_name}, {state}\")\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def fetch_weather_data(city: str, state: str, date_query: str):\n",
    "    coordinates = get_coordinates(city, state)\n",
    "    if not coordinates:\n",
    "        return {\"error\": \"City not found\"}\n",
    "    \n",
    "    lat, lon = coordinates\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if date_query.lower() == \"today\":\n",
    "        start_date = end_date\n",
    "    elif date_query.lower() == \"yesterday\":\n",
    "        start_date = (datetime.now() - timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "        end_date = start_date\n",
    "    elif \"last\" in date_query.lower():\n",
    "        if \"10 days\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(10)).strftime(\"%Y-%m-%d\")\n",
    "        elif \"30 days\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(30)).strftime(\"%Y-%m-%d\")\n",
    "        elif \"three months\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(90)).strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            return {\"error\": \"Invalid date query\"}\n",
    "    else:\n",
    "        try:\n",
    "            start_date, end_date = date_query.split('/')\n",
    "            datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            return {\"error\": \"Invalid date format. Use YYYY-MM-DD or predefined ranges.\"}\n",
    "\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": \"temperature_2m\"\n",
    "    }\n",
    "\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    response = responses[0]\n",
    "\n",
    "    location_info = {\n",
    "        \"Coordinates\": f\"{response.Latitude()}°N {response.Longitude()}°E\",\n",
    "        \"Elevation\": f\"{response.Elevation()} m asl\",\n",
    "        \"Timezone\": f\"{response.Timezone()} {response.TimezoneAbbreviation()}\",\n",
    "        \"Timezone difference to GMT+0\": f\"{response.UtcOffsetSeconds()} s\"\n",
    "    }\n",
    "\n",
    "    hourly = response.Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "    time_indices = list(range(0, len(hourly_temperature_2m), 6))\n",
    "    hourly_temperature_2m_6hr = hourly_temperature_2m[time_indices]\n",
    "\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            periods=len(hourly_temperature_2m_6hr),\n",
    "            freq='6H'\n",
    "        ),\n",
    "        \"temperature_2m\": hourly_temperature_2m_6hr\n",
    "    }\n",
    "\n",
    "    hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
    "\n",
    "    return location_info, hourly_dataframe\n",
    "\n",
    "weather_tool = StructuredTool.from_function(\n",
    "    func=fetch_weather_data,\n",
    "    name=\"Fetch_Weather_Data\",\n",
    "    description=\"Fetch weather data from a specified city and state, with a date query\",\n",
    "    args_schema=WeatherRequest,\n",
    "    return_direct=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "request = ElectricityPriceRequest(year=\"2024\", month=\"08\", day=\"06\", city=\"Oslo\", state=\"Oslo\")\n",
    "print(get_electricity_prices(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferenceInput(BaseModel):\n",
    "    minuend: int = Field(\n",
    "        description=\"The number from which another number is to be subtracted\"\n",
    "    )\n",
    "    subtrahend: int = Field(description=\"The number to be subtracted\")\n",
    "\n",
    "\n",
    "def get_difference(minuend: int, subtrahend: int) -> int:\n",
    "    return minuend - subtrahend\n",
    "\n",
    "\n",
    "difference_tool = StructuredTool.from_function(\n",
    "    func=get_difference,\n",
    "    name=\"Difference\",\n",
    "    description=\"Get the difference between two numbers\",\n",
    "    args_schema=DifferenceInput,\n",
    "    return_direct=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create the OpenAI LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tools to execute them from the graph\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tools = [weather_tool, difference_tool, electricity_tool, web_search_tool]\n",
    "\n",
    "executor = ToolExecutor(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Response(BaseModel):\n",
    "    electricity_prices: str = Field(description=\"Electricity prices for the specified query\")\n",
    "    real_time_info: str = Field(description=\"Real-time information fetched via web search\")\n",
    "#    sql_query_result: str = Field(description=\"Result from executing the SQL query on the database\")\n",
    "#   weather_data: str = Field()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create the tools to bind to the model\n",
    "tools = [convert_to_openai_function(t) for t in tools]\n",
    "tools.append(convert_to_openai_function(Response))\n",
    "\n",
    "# MODFIICATION: we're using bind_tools instead of bind_function\n",
    "model = {\"messages\": RunnablePassthrough()} | prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Agent State\n",
    "\n",
    "Everything from here onwards is new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Sequence[BaseMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the node actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    elif any(tool_call[\"function\"][\"name\"] == \"Response\" for tool_call in last_message.additional_kwargs[\"tool_calls\"]):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": messages + [response]}\n",
    "\n",
    "def call_tool(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    for tool_call in last_message.additional_kwargs[\"tool_calls\"]:\n",
    "        action = ToolInvocation(\n",
    "            tool=tool_call[\"function\"][\"name\"],\n",
    "            tool_input=json.loads(tool_call[\"function\"][\"arguments\"]),\n",
    "            id=tool_call[\"id\"],\n",
    "        )\n",
    "        try:\n",
    "            response = tool_executor.invoke(action)\n",
    "            function_message = ToolMessage(\n",
    "                content=str(response), name=action.tool, tool_call_id=tool_call[\"id\"]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            function_message = ToolMessage(\n",
    "                content=f\"Error: {repr(e)}\", name=action.tool, tool_call_id=tool_call[\"id\"]\n",
    "            )\n",
    "        messages.append(function_message)\n",
    "    return {\"messages\": messages}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize a new graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Define the two Nodes we will cycle between\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"action\", call_tool)\n",
    "\n",
    "# Set the Starting Edge\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "# Set our Contitional Edges\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set the Normal Edges\n",
    "graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Compile the workflow\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADuAPMDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAYIBQcBAwQCCf/EAFMQAAEDBAADAgcJDAUJCQAAAAEAAgMEBQYRBxIhEzEIFBUWIkHRMlFTVVaSk5TTFyM1NlRhcXWBlbPUCUJ2kaEkNENSYnKCtMEYJTNEV2ODhbH/xAAaAQEBAAMBAQAAAAAAAAAAAAAAAQIDBAUG/8QAMhEBAAECAQkGBgIDAAAAAAAAAAECEQMEEiExUVJhodEFExRBkcEjMnGBsfAVM0JT4f/aAAwDAQACEQMRAD8A/VNERAREQEREBERARdFbWQW6kmqqmRsNPC0vfI7uaB3lR1lqrcuaKi6S1dutjxuK1RPMMj2+p072nm3/AO21wAB07m7htoovGdVNo/dS2ZyrvVvt7+Sqr6amf/qzTNYf8SvP51WT44oPrTPaumjwfHbfHyU1htsLfXyUkYJ9fU66nfXZXf5rWX4ooPqzPYs/g8eRocedVk+OKD60z2p51WT44oPrTPaufNay/FFB9WZ7E81rL8UUH1ZnsT4PHkuhx51WT44oPrTPannVZPjig+tM9q581rL8UUH1ZnsTzWsvxRQfVmexPg8eRocedVk+OKD60z2rluU2ZxAbd6Ak9wFSz2p5rWX4ooPqzPYuDitkcCDZ6Ag9CDSs9ifB48jQyUcrJmB8b2vY7uc07BX2o3JgVrgkM9pY6wVmwe2toETXa6afHrkeNdPSaT7xBAK9dkvFRNUy225xshusDA8uiBENTGToSxbJIG+jmEksPQkgse/GaKZjOom/5S2xmURFpQREQEREBERAREQEREBERAREQEREBERBGMm1c8jx+yv06CR0txnYd+myAs5R9LLE7/gUnUZu7fFc9x2rcD2U9LV0GwNjtHdlK3Z9XowSKTLoxPkoiNnvKzqgRa/PhCcLGkg8SsPBHQg36l+0X1J4QPC6GRzH8ScQY9pLXNdfaUEEd4I7Rc6PNZ+OFuyLPrljFqx/Ibiy21r7bWXuCjYbfBVMiEroXPMgeCAWjfJy8zgObqFGOB/Hm98RMbym53vDb1QC01txZG+Cnhc2aOCd7G07GMnke+oDW6cNcpcDykjSwE2LZLfOOVmyvDsX83bZUV7Ki6ZVRXyGa3ZBbOwPKXUrHEulO2ckhb6IG+cggDz27BuJ9lwLilgtotLrVVXCru9yseVwXKFscpqagzRxcgPaxSake3nLdNLQQT0QTy1eEdZqyHJ23PHckxm5WC0SX2a1XmjjiqaijYHblh5ZHMd1YW6LgQSAdKI5/wCFHcaXhVTZfi2EZA6lrK61xUlVc6WnZHUwVUzWufGw1Afvl9BpcAOeWI9WEuEDoOBeRw3zJ6+x8LWYdbrtgNzx0Uxu1NPVS17+R8ck7g8hwfosD+dztjb+UFbW4h8NMjvvg02TG7ZRRSZNaqez1LbfNO1jZZaOWnlfD2my0E9k5odvl2R111Qbcx67TX2y0lfUWutss07eZ1Bcez7eHqRp/ZvezfTfouPesiteU/G/GrRRU0ecXWzcPr/KwySWK93yjFREzmcGOJbIWkODdggn3vUvv/tC8K//AFLw/wDf1L9og2AoxnerfSUF7Zps9sq4nF3vwyPbHM38/oOLtHpzMb3a2Pdi+Z4/nFBJXY5fbbkFFHKYX1Nrq46mNsgAJYXMJAdpzTrv0R768PEceMYtLQt2Za+eCjYAN9XytBP6A3mcfzNK6Mn/ALaY48vPkyp1pOiIudiIiICIiAiIgIiICIiAiIgIiICIiAiIgxt/srL9bXUzpDBK17JoJ2jbopWODmPHv6IGx6xsHoSvNZsjFTUC23ER0N7Y3b6Xm6Sgd8kJPu2fn7xvTtFZteG72Sgv1L4vcKWOqiB5miQdWu9TmnvafzjRW6mqLZler8Lfyl2+TaT8lh+jHsTybSfksH0Y9iwAwRsILaW/X2lj1oMFcZeX9BlDz/iuPMif5U376eL7JZZmHv8AKS0bUoa0MaGtAa0DQA7guVFvMif5U376eL7JPMif5U376eL7JO7w9/lK2jalKKvvg5XnIOKlizCsvWT3Vstqym42en8VfGwGCBzQzm2w7d1Oz/gts+ZE/wAqb99PF9knd4e/yktG1I5aOnndzSQRyO7tvYCV8eTKP8kg+jHsUf8AMif5U376eL7JcjCJvXlF+cPe7eIf/kad3h7/ACktG1nampobJRyTzyQUNKzq+R5EbB6up7veCw1uglyO7U95qoH09FSh3k6nnY5kvM4Frp5GnRaS0lrWkbDXO5uruVnbQYRa6KrjrJWz3KtjIdHU3GofUOjOtbYHkhh1vq0DvPvlZ9SaqKItRpmfP9/eCaI1CIi0IIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgrv4FH4p8SP7fXn+IxWIVd/Ao/FPiR/b68/xGKxCAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiCu/gUfinxI/t9ef4jFYhV38Cj8U+JH9vrz/EYrEICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAi8V5u9PYrdLW1POY2crQ2NvM97nENa1o9ZLiAB75UXdkGWTHnitdop2HqI5q2R7wP9otj1v8w2Pzlb8PBrxIvGrjNlsmqqP/SS8FJuJfBeDJrdG+a64e+Ws7Jp3z0kgaKjp77ezjfv1Njd76sD5czD8hsf1qb7NdVVcsqrqWamqLZYJ6eZhjkikqJi17SNEEdn1BB0tvha9sesFn5IeBfwN+7rxxtFuq6ftcetZFzupc3bHwxuGoj6vvjy1mu/lLiO5ftWq1+DtwDq/But2Q0tgprTVuvFe6qfUVNRL2jIRsQwbEfpNYC7qepL3H16G3fLmYfkNj+tTfZp4WvbHrBZN0UI8uZh+Q2P61N9mspY8oqai4ttt2pIqKukY6SB9PKZYZ2tI5gHFrS142DykdQdtLuV3LjVk9dMX0T9JgskaIi5UEREBERAREQEREBERAREQEREBERAREQEREBERBEeJR/7stI9Ru1Hsf8Aygr1rycSvwZaP1tSfxAsXxAyCmxXB79d6u7R2KCjopZTc5Ye2bTENOpOz/r6OjyDq7u9a9Kj+mn6z7L5M+iqfZeOXEHFJ81pbjHecgNJh8+S2o5FaKagqXSRPDC3s6Zx3EedrtPDZBykfnXTFxxybCbhebrJnMXEqzW/BpcheylpaaGGGtdLE2KN7oWbDHDnLQXcwAeTzdCMM+EW2RVxwLKeMDMitM11o75X2Otp533Ka70FrpYKF3YufFJTGmqHyObzhreWQPOnb5theHh5xEz+Gw8FspvuVi+UuaTxW+vtZt0EEcTpKSWWOaN7Gh4eHQ+ltxaeY8rWDQFzhZpkjJC4Nc1xaeVwB3o+8f7wsPdTrLsO166+YH9HidQf+gWmvBVx67W+XiBVVmU191pW5Zd6Y0NRT0zI3TNqBuoLo4mv53aO2h3IOY6aOmtyXb8bsM/WE3/J1C3YU3vPCr8SsJ8iIvJQREQEREBERAREQEREBERAREQEREBERAREQEREER4lfgy0frak/iBeDNcPtmf4pdccvMTprZcoHU87GPLHcp9bXDuIOiD74CkOY2eS82XkgfGypppoquEynlYXRvD+Vx0dBwBbvR1vejpa6wrjdjXEOzG6Y/5Ru1G2V0EktDQS1LGSN1zML4muYSNjucQd7BI6r08GO8wopp0zEz7MtcaEcn4AQ2qW53+DI8qyHKJLHV2Zk9ddo4pJ4ZACyMPbEGwua9oc2RjQ4OJLufuUE4LcI8wttzqrJeLLXWvh3W22opbpZ7/VWyp8akeGtZ2PiMMZa0N7QOLzshw6Aja37550/wAVX79yVf2aeedP8VX79yVf2az8PXuyZs7EYwXgnTYHJyQ5ZlV2t8dI+hpbbdbi2anpYna0GNDGlxaGgNdIXkDoD1K+6DgfYrdjGAWKOruLqTCqqGrt73yR9pK+OGSFomPJpw5ZXE8ob1A7u45KycV7Bk0NTLZ/KN1ipah9JO+htlRM2KZnu4nFrDyvbsbaeo31WS886f4qv37kq/s1e4r3ZM2djDYrwmoMMzK93613e7xQXiokrKmyPqGOoBUycvaTtYWc4e7l2fT5dk9Fnbt+N2GfrCb/AJOoXX550/xVfv3JV/ZqPXfiVYLPxFwqhyCokx91xqJo7SLjA+N1bVcnZ9mNj736Mp0XlvMXANB6qxTOFEzVFotPOJgiJjW3GiIvHYiIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAsFnOZW/h7iN1yS6tqXW62wGeZtHTunlLR6msaCSeo/MO8kAEjCcTOIN1wqkszrDiNxzSquNzjt7oba9jW0rSSZJZXuOmNa1ru/pzaaS3e12YrwzZjWe5VlUl/vN2qb6Ymtoq2qLqWhhjb6McMQ0B6Tnu2evpa98uDHW6iyPO8mw/MqbILljeKi2maoxGqtzIqmeokadeMvdtzeQO9w3+s3fMVPLdbaS0UcdJQ0sNFSx75IKeMRsbsknTQABskn9q9KIC0x4XPG5vAbgjer7BMI73VDyfaR0341I06fo/6jQ5/Xv5NetbnWnfCH8FvFfCXjsMeUXG9UUdmM7oGWmoiiEhl7PmLw+N+yOzGta1zO799Aob/Rq8eX4TxXq8Ju9WfJWWEGB8z+kde0EsOyf9I3bD6y4Rhfqovzo8GbwE8F4hUWSXuqvuUW25Y/lldbKGa21kEZYymkZ2Uh5oHffNnZI0NgaAX6LoC6aijp6zsu3gjn7J4lj7RgdyPHc4b7iN967kQapqrXknBu153k1LXZHxNZWVLa+hxhxiM1JzP++x079Almncwj9Qj00FziTsHH8hgv8AbLdVdjPb6ispI6zydXNEdVCx4B1JHs8rgToj1EELKqI3bhVjN54h2bOqm3E5TaaeSlpa+Od7D2Lw4GN7QeV7fTcQHA6J2EEuRantvFK6cMcPdcONlfjuOSyXfydR3C2zSmlqWPG4XOD27iOg8HZ0AwuJA7trMe2VjXscHscNtc07BHvhB9IiICIiAiIgIiICIiAuvxiL4RnzguxajznN7Tw7xqpvl6mfFRwFjAyGMySyyPcGsjjYOrnucQAB76DbHjEXwjPnBPGIvhGfOCr8/jjb7di9zvl9xzI8ZhonwxMprpQtE9ZJK7lijgbG94ke52hy7BBI3peCbwjsfttlyKtvNovthrLDDBVVlpuNIxtX2E0nZsmja2RzZGc2weVxILSCN6BCyHjEXwjPnBPGIvhGfOCrseOcE8eRUceNX233+2Wl13gtlzpoo5KyDZaJI9S60HAAte5jhsbAUMl483qt8G6izKutN9xy41NPRdpcqOhpKlrTK1jjUxQvqNGAk8oDyHjnHo9DoLb1dypKCmlqKmqhp6eJpfJLJIGta0d5JPcFDKrKMnuefWOks9pttTgNVb31VdkElx5ZudwIiigiaN79y4uJ1yuOiCADqvKPCEs+L3nKLe7H8iuYxjs33ert9HG+ClifAyYSlzpGlzQxx2GgvHI48utEyqx8RrTkWXV+PUInlqKS3Ut0NTyt7CSGoMgj5DvZP3pxO2jvHU+oJrwx4a4zwhxnyFjcT6eidUSVcr6mpfPNPM87fI97yS5x0P7lLfGIvhGfOCrjR+ETY7vjuN3K0WW/Xusv1K+upbPQUsb6xlO13I6WXcgjY0OIGy/qTobO9TTBs5tvEKwi62wVETGzSU09NWRGKemnjcWyRSMPVr2kaI/aCQQUG3kREBERBXbwKPxS4kf2+vP8RisSq7eBR+KXEj+315/iMViUBERAREQeG92K25LbJ7bd7fS3S3zgCWlrIWyxP0djbXAg6IB/YoXV41k2O8Qb/mMeTXG8Y3JaSGYYymjdy1MQBa6nkOiC8B4LT3ueCXaADdhL5k9w79BQRThrxDg4jYZbb+61XHHZKsOa+2XqA09VC9ri1zXMP52nR9Y0VKfGIvhGfOC1LnGcW7ALMy4XFtROZp2UtLR0URlqKqd++SKJg9046J9QABJIAJUKqvCNx+1WK+193tF+slXZTSGstNbRt8cbFUzCGKVjWPc2RheTssc4+g4a3oELH+MRfCM+cE8Yi+EZ84LQVo432Srqb/T3ihueJVNloBdamK+wsjJozzjt2GN7wW7Y4EbDgRogFQ+2cdLjmPFzALXb7RfsfsN1pLjUyi9W+OFtwYyOJ0L4ztz2gbcdHkOnt2NEILXte1421wcPzHa+lhsY/wA0l/3/APoFmUBERAREQFX3jlhN2zTFLa+wtgmvVku9He6SkqpOziqn08gf2Ln6PLzDYB10Ov0qwSx/kGh+BPz3e1BWXNrfnPFPFYJ34WMcu2P3e33u3UNfdIJvKEkEhdJE50Rc2MFvRriTskbDdbUP4jcNM84rxZtkM+MeQq2psdLY7ZZJa+CWecNrG1Es0j2v7No6aaOcnQcTokBXK8g0PwJ+e72p5BofgT893tQaByPA7teuNTruyAMssuH1lndWl7fQqJKmJzW8m+Y+i1x3rXTW9lQF+E53efBdqeH1XiTqG92qgoLbSvFwp5Irh2MkYdJGQ8cg5Yg7UnKfS1roreeQaH4E/Pd7U8g0PwJ+efagrVX8PMgnrOPL2W/mZk9JFFaT20f+UuFsEBHuvQ++Dl9Pl9/u6rF41iea8OcpoLtQ4v5ebX4nbLRURsuEMHiNXTdpvtS53pRntfdR85HKdNOwt34tlVhq+IN64ePZdai/2Khpq2atuELWMrIpuYCSN0Ya06LeU6a0b2ADp2p15BofgT893tQUUsHg837H7Vw+u174e27OpKDHTY7njlZPTGWkkFQ+aOeF8juyd/4jmuHMDojW+oVk+GWPUuN4hS09NitDhjpXOnms9udG6OF5OurmNDXOLQ3ZA7+mzra2x5BofgT893tTyDQ/An57vagyCIiAtJeEZxnumIeS8EwWKO5cT8o3DbKY9WUMPUSVs3fysYA4jY6kHoQ1wUq458ZrXwQwiS9VkMlxuVRI2jtNnp+s9xq39I4WAbPU95AOgD0J0DFfB04MXPEDdc7zqWO48T8o1Nc6hvpMoIehjooe/TGANB0epaOpDWlBLuBvCGi4JcPaTHKWrnudW6R9ZcbnUuJkrayQ7lmdsnWz3D1ADZJ2TP0RAREQEREBfMnuHfoK+lwRsEHuQVq8IvhlW8R8dsEtvtlDf6mxXeK6Oslyc1sFxiDHxyQlzgWtcWyEtc4aBA2oTeuEs964VZJS2DhPbsEvNXWW4RUlLPSdtUwxVkE0jpHREMaGhryG85J175AVvPIND8Cfnu9qeQaH4E/Pd7UFWeM3Bm+cTMvyttKxlLb7phXkiCvkkbyCsFWZmsc0Hn5dcuzy60T3nou610ufZnxX4e3y/YMcZpLFSXGGtm8p01QwyzRxNb2bWOLuQmM6JG+vUDvO7uFdkmkx+sN2ymhzSo8oVAZX29jI2RR8/owERkjmjHoknqfWpl5BofgT893tQebGP80l/wB//oFmV0UtHDRMLYW8jSdkbJXegIiICIiAiIgIiICIiCGcTqTNqi32h+CVdspa+K6U0lfHdGEsqKIO+/RtcASxxB2HAE9CBonaxt48IjhvY81s+I1OYW6TJbtUClpbbRvNTL2h5S1snZBwh5g9pBkLQ7Z1vR1BPDPoeMNdwxLOElRDE8NmF3ggYDcZ4HM5QymLgQDpzyeXUmwzkcCCHflf4NrZrV4SnDaKeJ9PPHk9BDJFI0tcxxqGNIIPceukH7oIiICwuaZlZ+HuK3PI7/Wx26z26Ez1FRJ3NaPUB3lxOgGjqSQB1Ky8srIInySPbHGwFznvOg0DvJPqCqtb45PDR4ksudQx33EMUrT4lA8EMyW4RnRmcP61PGdgDuce/e3BgZbgdhd441Z1Hxwz2jkpI+zdHhmO1HdbKN3/AJqRvd28o0d+oEf7IZZZcAAAADQHqC5QEREBERAREQEREBR3LuI+JcP/ABTzoyiy4343z+LeV7hDS9tycvPydo4c3LzN3ru5h74UiVUf6RnghJxT4J+cFvifNe8RdJXRsafd0rg0VLde+Axkm/eiIHegk3ArjnwIsuK19NjWX2bHaOS7Vcr6O+XmCKeSd0m3yta+UkxvPVpHQjuViF+P/wDR78DPuucb6e73CnEuPYsGXGpD27ZLPs+LxH/iBeQehETge9fsAgIiICIiAiIgIiICIiAondshudbdKq32R9JTiic2OprKuJ0wEha1/ZsY17TsMc0lxOhzNADuupYoDjxJu+U7O9XZ2voYV2ZPTE51Uxe0e8LD75sx+PrT+55P5hamz/wYKHiLxEx7Oa+rttFlNlrqevjuFutb4nVLoXtexs47ciQba0b0HaGg4BbxRdWfwj0jot2H5sx+PrT+55P5hObMfj60/ueT+YXqkvlvivUFofWwNuk8D6qOjMg7V8THNa6QN7+UF7QT3bcF57flVruuQXeyUtSZbnaWwurIOye3shK0uj9IgNdsNPuSda66TP4R6R0LojxS4d5NxYwquxe4ZjHa7bXgMqn2q2mKWaLfpRFxmdpju52tEjpvRIOaxrHb9h9gt9ks1yslutVBC2npqWGzSBsbGjQA/wAp/wAT1J6nqpUiZ/CPSOhd5rTkNyorpS2+9vpKgVrnR01ZSROhBkDXP7N7HPcdljXEOB0eUghvTcsUByEkXfFtHW7s3f0Myny5copiM2qItePdJERFxoIiICxmQ5Hb8Wtrq65VAggDgxo1t0jz3Na0dXOOj0HvE9wKyarXlGUyZvfpro6QvoWOdHb49+iyHu59f6z9cxPvFo9S9Ts/IpyzEmJm1Ma+n3XilV2433urkPke2Ulvg/qvuXNNIf0sjc0N/Y9yxh4t5nvpVWgf/XyfbKLIvtKez8loi0Ycfn8sc6Uo+61mf5XZ/wB3SfbL5m4q5hURPilqLNJG9pa5j7a8hwPQgjtuoUZRZ+Byb/XHoZ0sPwYs9TwEx2tsuJm2wUdZWyV0rqiifJIXu0A3m7Uei1oDWj1AdSSSTsD7rWZ/ldn/AHdJ9sousdW5Fb7fe7baKio7O4XJsr6WHkce0EQaZOoGhoOb3kb302pOR5LGvDj0hc6U5+61mf5XZ/3dJ9su+m4x5dTvDpm2esjHfGKaWFx/4+0cB80qIIk5Dks6Jw49EzpbywvilbstqG0M0L7XdSCW0szg5swA2TE8e60OuiA7oTrQ2poqryR84aQ98cjHB7JY3cr43A7Dmn1EHqCt+8M8tkzDF46ipLTcaaQ0lZyjQMrQDzAeoOa5r9erm0vlu0+zqcmiMXC+XZs/4y1pWiIvnkEREBERAUAx78L5V+tnfwYVP1AMe/C+VfrZ38GFd2Taq/p7wsapaE8IW6Xe/wCTZHR4jV5LFdcYsba6tnoshNrt9EXCV8TjG2N5qZXCNxLHDk5WNG2klfViv1644ZritiuuR3XH7b5jUGSTQ2GrdQz19VUuLXuMrNPEcfL7lpA5njexoLb2W8FcLzq/C83yxsrq8wtppXdvLHHURNJLY542PDJmgk6EjXAbK8d28H/Ar1ZrDa6qxONNYYfF7ZJDW1EVRSxa12bZ2SCTk0AOUuI0ANdFc2bo1pduG1I7wosLpKi+5HMabEKp4qTeqiKWZ0NXSgc5jc0ODg4l7dafoFwOgo7nWW5Fh2T8X7da8iulPDU3rHaKGsq6x9QLRHXP5aiSASEtiA5zygABp5dDoFvO8cCcHv1ssFBV2QiCwsdHbXU9ZPBLTscAHNEkb2vLXaGwSQdDe1lLhwuxa7S5PJXWeGsOSxQw3ZlQ572VTYmlkYLSdN5QehaAd6PeAUzZFbOMl4v3Bt3EDGrHl2QV1I7B5L9DPcrlJU1dvqo6pkIdHO487WyNefRJ1uM60NhbOxyluOB+EBaLBHkV6vNqveN1VdUw3iudU8tVBPA0Sx83SLmbM8FjA1ndpo0pTQ+D1w/t2PX6yRWEvob7C2nuTqitqJp6iJvuWGd8hlDR10A4AbOlLZsQtFRlNDkclJzXmipJaGnqe0eOSGRzHPZy75TsxsOyCRroRspFMjryH8L4r+tm/wAGZT9QDIfwviv62b/BmU/Uyn5aPp7ys6oERFwoIiIMXlUksWMXh8G+3bRzGPXfzch1/iqyWwNbbaQM9wImAdNdNBWuc0PaWuALSNEH1qsd2x2XDrxU2SUEMpzule7/AEtOT97cD6yB6J/O0+ohfWdhYlMd5hzr0STqeZFhMip8knfB5BuFromAHtRcaGSpLj01y8k0evX37/YsR5P4ha/D2M7/AFJUfza+omuYm2bM+nVgwvHXIrxZ7Rj1vs0hp573d4bdJUCp8WLWOY93K2Xkf2bnlgaHBpI2dddEQbJqDPcKwPJpqq6T2+ifLbhQubepLhV00prI2ykTSRMPI5rgOV3MO/1OIW1n4hccottba82fZb7a52t5aejoJaYtcDvmLnTvOx00W6IPrXNLwmxWjsNZZo7a91BWTRT1DZauaR8r43NdGTI55f0LG9N66a7lxYmDiYtVVUTa8aNOrRbyifrrVrHM8ku/CK65nT2u53G6QxYw27QMutS+qMFT27oi9pfshuiHFnd6PQBe2nw/zW4vcOJHZBdsgkqqK5OknuVYZ2OcIoSXxg9GB3N3N6aA6LbFZiNnuF4qLpU0LKisqKE22V0hc5slMXFxjLCeUgknrrfXW9KNWzgzjeLTxXDHLfHQXikikioairnqKmKAPABb2ZlHodB6II16tKTk9edeNMXiY06rTfmJ4ihht/EP1X7Gf3JUfza7aWhzxtVCam945JTh4MjIrPUMe5u+oa41RAOu4kH9BXZnzuzy6oly2TwEc/xrJ29ey7SncOnTnLHA/wCAYtZzTMgidJI7lY0bJW9OE2LT4xi3NWRmK4XCU1lRG7vjJa1rGH87WNaD/tcy8rtjEpoyWaJ11Wt9puzjzTVERfBAiIgIiIChlztVxsV3rq230D7tR18jZpaeCRjJoZQxrCW9o5rXMLWA62CCD7rm9GZotuHiThTeNN1ibID5bvPyLvf01D/Mp5bvPyLvf01D/MqfIunxUbkc+q3jYgPlu8/Iu9/TUP8AMp5bvPyLvf01D/MqfInio3I59S8bEB8t3n5F3v6ah/mU8t3n5F3v6ah/mVPkTxUbkc+peNiGWy1XG+3ahrbhQPtNHQSGeKnnkY+aaUscwF3Zuc1rAHk62SSR7nl9KZoi5sTEnFm86LJM3ERFqQREQFgsuw635lb209a1zJYnc8FTEdSQu1rYPrB9YOwf7lnUWdFdWHVFdE2mBoK7cJ8rtLyKanp77CPcyU0rYJT+mOQho/Y8/sWMOEZeCR5p15/RU0n26sgi96ntzKaYtNNM/afaYXRsVu8ycv8AklX/AFmk+3TzJy/5JV/1mk+3VkUWf87lG5Tz6mjYrd5k5f8AJKv+s0n26eZOX/JKv+s0n26siifzuUblPPqaNit3mTl/ySr/AKzSfbrvpuHmY1cgYMdfSb/0lZWQNYP09m97v7gVYpFJ7dyif8KefU0bGucI4Rx2OshuV5qI7jcInc8MMTSIIHe+N9XuHqcda9QB6rYyIvEx8oxMprz8WbygiIucf//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to display graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import uuid\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import threading\n",
    "import uuid\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "final_output = {\"content\": \"\", \"tool_calls\": []}\n",
    "\n",
    "def _print_event(event, printed_set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(f\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in printed_set:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            printed_set.add(message.id)\n",
    "            if isinstance(message, AIMessage):\n",
    "                final_output[\"content\"] = message.content\n",
    "                final_output[\"tool_calls\"] = message.additional_kwargs.get(\"tool_calls\", [])\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"]\n",
    "            ) for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def stream_events(question, config):\n",
    "    events = app.stream(\n",
    "        {\"messages\": [HumanMessage(content=question)]}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "\n",
    "def process_question(question, config):\n",
    "    stream_events(question, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What was the weather at Lillehammer yesterday? Are the electricityprices correlated with the weather?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (process_question):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_200663/1280444440.py\", line 50, in process_question\n",
      "  File \"/tmp/ipykernel_200663/1280444440.py\", line 46, in stream_events\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 1110, in stream\n",
      "    _panic_or_proceed(done, inflight, step)\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 1780, in _panic_or_proceed\n",
      "    raise exc\n",
      "  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langgraph/pregel/retry.py\", line 72, in run_with_retry\n",
      "    task.proc.invoke(task.input, task.config)\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2822, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langgraph/utils.py\", line 102, in invoke\n",
      "    ret = context.run(self.func, input, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_200663/1290715829.py\", line 22, in call_model\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2824, in invoke\n",
      "    input = step.invoke(input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5006, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 265, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 698, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 555, in generate\n",
      "    raise e\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 545, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 770, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 582, in _generate\n",
      "    return generate_from_stream(stream_iter)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 97, in generate_from_stream\n",
      "    generation = next(stream, None)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 520, in _stream\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/openai/_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[4].function.description': string too long. Expected a string with maximum length 1024, but got a string with length 1824 instead.\", 'type': 'invalid_request_error', 'param': 'tools[4].function.description', 'code': 'string_above_max_length'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output Content: \n",
      "Tool Calls: []\n"
     ]
    }
   ],
   "source": [
    "# Setup threading and configuration\n",
    "questions = [\n",
    "    \"What is magic_function(3)\",\n",
    "    \"What was the weather at Lillehammer yesterday? Are the electricityprices correlated with the weather?\",\n",
    "    \"Was it warmer in Lillehammer than Hamar yesterday?\"\n",
    "]\n",
    "\n",
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": thread_id,  # Checkpoints are accessed by thread_id\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start the thread\n",
    "thread = threading.Thread(target=process_question, args=(questions[1], config))\n",
    "thread.start()\n",
    "\n",
    "# Wait for the thread to complete\n",
    "thread.join()\n",
    "\n",
    "# Access the final output\n",
    "print(\"Final Output Content:\", final_output[\"content\"])\n",
    "print(\"Tool Calls:\", final_output[\"tool_calls\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
