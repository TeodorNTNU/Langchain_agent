{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtavily_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TavilySearchResults\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_ollama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OllamaEmbeddings\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_ollama'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import sys\n",
    "import uuid\n",
    "from psycopg_pool import ConnectionPool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set API keys\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Optionally, add tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"llama3-tool-use-agent\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "\n",
    "#ASTRA\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_API_ENDPOINT = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "ASTRA_DB_KEYSPACE = os.getenv(\"ASTRA_DB_KEYSPACE\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI Embeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "GPT3 = 'gpt-3.5-turbo'\n",
    "GPT4 = \"gpt-4o-mini\"\n",
    "NOMIC = 'nomic-embed-text:latest'\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=NOMIC)\n",
    "\n",
    "llm=ChatOpenAI(model=GPT3,temperature=0)\n",
    "# experiment_prefix=\"sql-agent-gpt4o\"\n",
    "# metadata = \"Chinook, gpt-4o base-case-agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='magic_function' description='Applies a magic function to an input.' args_schema=<class 'pydantic.v1.main.magic_functionSchema'> func=<function magic_function at 0x7c0a5cd9dee0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pydantic.v1.main.magic_functionSchema"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "@tool\n",
    "def get_coordinates(city_name: str, state: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Get the latitude and longitude for a given city and state.\n",
    "    \n",
    "    Args:\n",
    "    - city_name (str): The name of the city.\n",
    "    - state (str): The name of the state.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: A tuple containing the latitude and longitude of the location.\n",
    "    \"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"weather_api\")\n",
    "    location = geolocator.geocode(f\"{city_name}, {state}\")\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "@tool\n",
    "def fetch_weather_data(city_name: str, state: str, date_query: str):\n",
    "    \"\"\"\n",
    "    Fetch weather data for a given city, state, and date query.\n",
    "    \n",
    "    Args:\n",
    "    - city_name (str): The name of the city.\n",
    "    - state (str): The name of the state.\n",
    "    - date_query (str): The date query which can be \"today\", \"yesterday\", \"last 10 days\", \n",
    "                        \"last 30 days\", \"last three months\", or specific date range \"YYYY-MM-DD/YYYY-MM-DD\".\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing location information and a DataFrame of the weather data.\n",
    "    \"\"\"\n",
    "    coordinates = get_coordinates(city_name, state)\n",
    "    if not coordinates:\n",
    "        return {\"error\": \"City not found\"}\n",
    "    \n",
    "    lat, lon = coordinates\n",
    "\n",
    "    # Calculate dates based on query\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if date_query.lower() == \"today\":\n",
    "        start_date = end_date\n",
    "    elif date_query.lower() == \"yesterday\":\n",
    "        start_date = (datetime.now() - timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "        end_date = start_date\n",
    "    elif \"last\" in date_query.lower():\n",
    "        if \"10 days\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(10)).strftime(\"%Y-%m-%d\")\n",
    "        elif \"30 days\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(30)).strftime(\"%Y-%m-%d\")\n",
    "        elif \"three months\" in date_query.lower():\n",
    "            start_date = (datetime.now() - timedelta(90)).strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            return {\"error\": \"Invalid date query\"}\n",
    "    else:\n",
    "        try:\n",
    "            # Specific date range\n",
    "            start_date, end_date = date_query.split('/')\n",
    "            # Validate dates\n",
    "            datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            return {\"error\": \"Invalid date format. Use YYYY-MM-DD or predefined ranges.\"}\n",
    "\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    # Define the API endpoint and parameters\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": \"temperature_2m\"\n",
    "    }\n",
    "\n",
    "    # Fetch the weather data\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    response = responses[0]\n",
    "\n",
    "    # Display location information\n",
    "    location_info = {\n",
    "        \"Coordinates\": f\"{response.Latitude()}°N {response.Longitude()}°E\",\n",
    "        \"Elevation\": f\"{response.Elevation()} m asl\",\n",
    "        \"Timezone\": f\"{response.Timezone()} {response.TimezoneAbbreviation()}\",\n",
    "        \"Timezone difference to GMT+0\": f\"{response.UtcOffsetSeconds()} s\"\n",
    "    }\n",
    "\n",
    "    # Process hourly data\n",
    "    hourly = response.Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "\n",
    "    # Get every sixth hour\n",
    "    time_indices = list(range(0, len(hourly_temperature_2m), 6))\n",
    "    hourly_temperature_2m_6hr = hourly_temperature_2m[time_indices]\n",
    "\n",
    "    # Generate dates for every sixth hour\n",
    "    hourly_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            periods=len(hourly_temperature_2m_6hr),\n",
    "            freq='6H'\n",
    "        ),\n",
    "        \"temperature_2m\": hourly_temperature_2m_6hr\n",
    "    }\n",
    "\n",
    "    hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
    "\n",
    "    return {\"location_info\": location_info, \"weather_data\": hourly_dataframe.to_dict(orient='records')}\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_electricity_prices(year: str, month: str, day: str, region: str) -> str:\n",
    "    \"\"\"Fetches electricity prices for a given date and region.\"\"\"\n",
    "    import requests\n",
    "    url = f\"https://www.hvakosterstrommen.no/api/v1/prices/{year}/{month}-{day}_{region}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return json.dumps(response.json(), indent=4)\n",
    "    else:\n",
    "        return f\"Error fetching data: {response.status_code}\"\n",
    "\n",
    "@tool\n",
    "def web_search(input: str) -> str:\n",
    "    \"\"\"Runs web search.\"\"\"\n",
    "    web_search_tool = TavilySearchResults()\n",
    "    docs = web_search_tool.invoke({\"query\": input})\n",
    "    return docs\n",
    "\n",
    "# @tool\n",
    "# def image2text(image_url: str, prompt: str) -> str:\n",
    "#     \"\"\"generate text for image_url based on prompt.\"\"\"\n",
    "#     input = {\n",
    "#         \"image\": image_url,\n",
    "#         \"prompt\": prompt\n",
    "#     }\n",
    "#     output = replicate.run(\n",
    "#         \"yorickvp/llava-13b:b5f612031823083fd4b6dda3e32fd8a0e75dc39d8a4191bb742157fb\",\n",
    "#         input=input\n",
    "#     )\n",
    "#     return \"\".join(output)\n",
    "# \n",
    "# @tool\n",
    "# def text2speech(text: str) -> int:\n",
    "#     \"\"\"convert text to a speech.\"\"\"\n",
    "#     output = replicate.run(\n",
    "#         \"cjwbw/seamless_communication:668a4fec05a8871a54e5fe8d45df25ec4c794dd43169b9a11562309b2d45873b0\",\n",
    "#         input={\n",
    "#             \"task_name\": \"T2ST (Text to Speech translation)\",\n",
    "#             \"input_text\": text,\n",
    "#             \"input_text_language\": \"English\",\n",
    "#             \"max_input_audio_length\": 60,\n",
    "#             \"target_language_text_only\": \"English\",\n",
    "#             \"target_language_with_speech\": \"English\"\n",
    "#         }\n",
    "#     )\n",
    "#     return output\n",
    "\n",
    "custom_tools = [magic_function, \n",
    "                web_search, \n",
    "                fetch_electricity_prices, \n",
    "                fetch_weather_data,\n",
    "                get_coordinates]\n",
    "\n",
    "print(magic_function)\n",
    "magic_function.args_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['checkpoints', 'prices', 'products']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///test.db\")\n",
    "\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoint.sqlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLDatabaseToolkit\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msqlite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SqliteSaver\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m END, MessageGraph\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool_node\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolNode\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph.checkpoint.sqlite'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import tool\n",
    "\n",
    "# SQL toolkit\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "sql_tools = toolkit.get_tools()\n",
    "\n",
    "# Define the SQL instructions\n",
    "sql_instructions = \"\"\"\n",
    "SQL DATABASE INSTRUCTIONS:\n",
    "- Start by reviewing the tables in the database to understand what you can query.\n",
    "- Query the schema of relevant tables.\n",
    "- Write and double-check your query based on the table schema.\n",
    "- Limit your query to at most 5 results unless specified otherwise.\n",
    "- Order results by relevant columns to return the most interesting examples.\n",
    "- Query only relevant columns for the question.\n",
    "- If an error occurs, rewrite the query and try again.\n",
    "- Use the check_result tool to verify query results.\n",
    "- If the query returns no results, rethink the schema and try again.\n",
    "- DO NOT perform DML operations (INSERT, UPDATE, DELETE, DROP, etc.).\n",
    "\"\"\"\n",
    "\n",
    "# Query checking\n",
    "query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "Double check the SQLite query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "Execute the correct query with the appropriate tool.\"\"\"\n",
    "query_check_prompt = ChatPromptTemplate.from_messages([(\"system\", query_check_system), (\"user\", \"{query}\")])\n",
    "query_check = query_check_prompt | llm\n",
    "\n",
    "@tool\n",
    "def check_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to double check if your query is correct before executing it.\n",
    "    \"\"\"\n",
    "    return query_check.invoke({\"query\": query}).content\n",
    "\n",
    "# Query result checking\n",
    "query_result_check_system = \"\"\"You are grading the result of a SQL query from a DB.\n",
    "- Check that the result is not empty.\n",
    "- If it is empty, instruct the system to re-try!\"\"\"\n",
    "query_result_check_prompt = ChatPromptTemplate.from_messages([(\"system\", query_result_check_system), (\"user\", \"{query_result}\")])\n",
    "query_result_check = query_result_check_prompt | llm\n",
    "\n",
    "@tool\n",
    "def check_result(query_result: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to check the query result from the database to confirm it is not empty and is relevant.\n",
    "    \"\"\"\n",
    "    return query_result_check.invoke({\"query_result\": query_result}).content\n",
    "\n",
    "# Combine all SQL tools and instructions\n",
    "sql_tools_with_instructions = sql_tools + [check_query_tool, check_result]\n",
    "\n",
    "tools = custom_tools + sql_tools_with_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m      4\u001b[0m primary_assistant_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m      5\u001b[0m     [\n\u001b[1;32m      6\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     ]\n\u001b[1;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mpartial(time\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# LLM chain\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m assistant_runnable \u001b[38;5;241m=\u001b[39m primary_assistant_prompt \u001b[38;5;241m|\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39mbind_tools(tools)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \n",
    "         \"You are a helpful assistant with tools for (1) web search, (2) weather data fetch, and (3) electricity price fetch. \"\n",
    "         \"Use web search for real-time queries and current events, weather data fetch for weather-related questions, and electricity price fetch for price-related queries. \"\n",
    "         \"For database questions, follow SQL instructions. Determine the appropriate tool based on the question, fetch the necessary data, and return the answer. \"\n",
    "         \"Current time: {time}.\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "        (\"system\",\n",
    "         \"\"\"\n",
    "         ROLE:\n",
    "         You interact with various data sources using specific tools to answer questions accurately.\n",
    "         GOAL:\n",
    "         Use the appropriate tool for the input question, retrieve data, and provide a relevant answer.\n",
    "         INSTRUCTIONS:\n",
    "         - Use tools only for their specified operations.\n",
    "         - Construct your final answer using tool outputs.\n",
    "         - For weather questions, use the weather data fetch tool.\n",
    "         - For electricity price queries, use the electricity price fetch tool.\n",
    "         - For real-time information, use the web search tool.\n",
    "         - For database questions, follow SQL instructions.\n",
    "         \"\"\")\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "# LLM chain\n",
    "#llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'magic_function',\n",
       "  'args': {'input': 3},\n",
       "  'id': 'call_9znIrSH5MkzkkiPV6kPtoJjO',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is magic_function(3)?\"\n",
    "payload = assistant_runnable.invoke({\"messages\": [(\"user\", question)]})\n",
    "payload.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'web_search',\n",
       "  'args': {'input': 'Capital of the United States'},\n",
       "  'id': 'call_G83iCjXqnig8o4mYSInnDg6O',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of the US?\"\n",
    "payload = assistant_runnable.invoke({\"messages\": [(\"user\", question)]})\n",
    "payload.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'sql_db_query',\n",
       "  'args': {'query': 'SELECT product_name, brand, MIN(price) AS cheapest_price FROM test GROUP BY product_name ORDER BY cheapest_price LIMIT 1'},\n",
       "  'id': 'call_Gb3aQE5akI5bUjXXu46ksvt2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Hvilket produkt er billigst fra test databasen? Og Hvilket merke er det?\"\n",
    "payload = assistant_runnable.invoke({\"messages\": [(\"user\", question)]})\n",
    "payload.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory/State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "# Define the State type\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "embedding_size = 384 # Dimensions of the OpenAIEmbeddings\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "embedding_fn = embeddings.embed_query\n",
    "vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The embedding saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableConfig, Runnable\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            # Invoke the tool-calling LLM\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If it is a tool call -> response is valid\n",
    "            # If it has meaningful text -> response is valid\n",
    "            # Otherwise, we re-prompt it because response is not meaningful\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                # Then we re-try\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "# Tool\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "# Utilities\n",
    "def _print_event(event: dict, _printed: set, max_length=1500) -> None:\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(f\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "            \n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"]\n",
    "            ) for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "assistant = Assistant(assistant_runnable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"assistant\", RunnableLambda((assistant)))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.set_entry_point(\"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    # 'Tools' calls one of our tools. END causses the graph to terminate(and repond to the user)\n",
    "        {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to display graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What was the weather at Lillehammer yesterday?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_jebc47X1xo9xUtTks8dI9pbz)\n",
      " Call ID: call_jebc47X1xo9xUtTks8dI9pbz\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Norway\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teodorrk/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_qkcKCAR1LAFUz5vdGcnPAjmR)\n",
      " Call ID: call_qkcKCAR1LAFUz5vdGcnPAjmR\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Norway\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_U2omccPPfmhydwq4cORGuT85)\n",
      " Call ID: call_U2omccPPfmhydwq4cORGuT85\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_jb7zCdvaGCKnAuKBNoMNgmJt)\n",
      " Call ID: call_jb7zCdvaGCKnAuKBNoMNgmJt\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_1SvogCrszdjQLEYBSwG1srCb)\n",
      " Call ID: call_1SvogCrszdjQLEYBSwG1srCb\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_uQ9N4WzlCy4LmJKUJWkPuyln)\n",
      " Call ID: call_uQ9N4WzlCy4LmJKUJWkPuyln\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_PqDHfT24k9NEHBWytMz55FI2)\n",
      " Call ID: call_PqDHfT24k9NEHBWytMz55FI2\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_xWtzfHDNvvlQ9TOQIVMyh4tW)\n",
      " Call ID: call_xWtzfHDNvvlQ9TOQIVMyh4tW\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_k5KabaLI6WibCThjrouk5AO4)\n",
      " Call ID: call_k5KabaLI6WibCThjrouk5AO4\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_SJXupS9HOtvbxa6Rpyd7EMiH)\n",
      " Call ID: call_SJXupS9HOtvbxa6Rpyd7EMiH\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_XtyOWLWdiKMkb0kHrqhxGpn3)\n",
      " Call ID: call_XtyOWLWdiKMkb0kHrqhxGpn3\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I encountered an error while trying to fetch the weather data for Lillehammer yesterday. Let me try again to retrieve the information for you.\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_dFHQYtmt3WttxRAB9btS428v)\n",
      " Call ID: call_dFHQYtmt3WttxRAB9btS428v\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_weather_data\n",
      "\n",
      "Error: AttributeError(\"'str' object has no attribute 'parent_run_id'\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_weather_data (call_rjedVMogZVULt6Cqt7c6YXCG)\n",
      " Call ID: call_rjedVMogZVULt6Cqt7c6YXCG\n",
      "  Args:\n",
      "    city_name: Lillehammer\n",
      "    state: Oppland\n",
      "    date_query: yesterday\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: thread_id,  \u001b[38;5;66;03m# Checkpoints are accessed by thread_id\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     16\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, questions[\u001b[38;5;241m1\u001b[39m])]}, config, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_print_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_printed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Langchain_agent/.myvenv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1170\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(read_channels(channels, output_keys))\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reachedwithout hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is magic_function(3)\",\n",
    "    \"What was the weather at Lillehammer yesterday?\",\n",
    "]\n",
    "\n",
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": thread_id,  # Checkpoints are accessed by thread_id\n",
    "    }\n",
    "}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", questions[1])]}, config, stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": ".myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
